\clearpage{\pagestyle{empty}\cleardoublepage}

\chapter{Event reconstruction}\label{chap:objects}

After having described the ATLAS detector in Chapter~\ref{chap:atlas} 
and the procedure for Monte Carlo simulation of events in Chapter~\ref{chap:mc},
we understand that what we deal with when we talk about ``data'' 
is raw digital signals from the detector,
either the real one or the simulated one.

In this chapter we will explain how, starting from these digital signals,
objects are reconstructed to be used in physics analyses~\cite{Aad:2009wy}. 
This process is what is called ``offline event reconstruction'' since
it is not done in real time, due to the time required by the algorithms
to perform their tasks.

In general we could describe the full procedure as subdivided into
three main steps: a pre-reconstruction stage where the electronic signals are
translated into measurements of positions, times, energies; 
a pattern-recognition step where the measurements
are assembled into the building blocks of particles, e.g. tracks and energy clusters;
a particle identification step where the information from relevant 
sub-detectors
is combined to reconstruct as accurately as possible 
a candidate physics object 
(electrons, muons, jets and the missing transverse energy \met).

The expected signatures for the various particles in terms of interaction
with the detector system are schematically shown in Figure~\ref{fig:decaychart}:
only charged particles (as electrons, muons, protons) leave tracks in the Inner
Detector; electrons and photons create particle showers in 
the Electromagnetic Calorimeter; hadrons deposit most of their energy
in the Hadronic Calorimeter; muons typically cross the whole
detector material reaching the Muon Spectrometer where their track is measured;
neutrinos cross completely undetected.

\begin{figure}[tb]\begin{center}
        \subfigure{
  	\includegraphics[width=0.7\textwidth]{objectsreconstruction/figures/particles}}
	\caption{Drawing illustrating how particles are detected in the ATLAS subsystems.
	\label{fig:decaychart}}
\end{center}\end{figure}

%In addition, some details from
%selections specific for the analyses presented in this dissertation will be given.

\section{Tracks}\label{sec:tracks}

Charged particles interact with the surrounding material by
leaving nearby matter ionized. In bubble chambers this can be
seen by eye as the detector material is, typically, gas in liquid
state at a temperature very close to transition back to gaseous state,
in a way that charged particles passing through would leave tracks of
small gas bubbles induced by ionization. In modern silicon detectors
a charged particle is ``seen'' as an electrical signal induced by the
ionization. Lorentz equation describes how moving charged particles
feel the action of a magnetic field, resulting in a helicoidal trajectory with a
radius of curvature proportional to their momentum. These properties allow
to measure direction and momentum of the charged particles crossing
the ID layers. Particle trajectories (``tracks'') are 
also used to identify the interaction vertices.
The parameters describing a track are: $q/p$, the charge divided by the momentum; $\theta$, or more commonly used $\eta$, the angle
with respect to the Z axis in the $R$Z plane measured from the 
perigee\footnote{The perigee is the point of the track closest to the origin.}; $\phi_0$, the angle 
with respect to the X axis in the XY plane measured from the perigee; $d_0$, the impact parameter, 
or perigee with respect to the Z axis in the XY plane; $z_0$, Z component of the perigee.
These parameters are shown in the double-view drawing of Figure~\ref{fig:trackpar}.

\begin{figure}[tb]\begin{center}
	\subfigure{
  	\includegraphics[width=0.7\textwidth]{objectsreconstruction/figures/tracks}}
	\caption[bla]{Schematic drawings of the parameters used for track 
        reconstruction in the XY and $R$Z planes (left and right respectively)
          where the origin is the beam spot, i.e. the region in the transverse plane where the protons collide.
\label{fig:trackpar}}
\end{center}\end{figure}

In order to reconstruct the track, the first step is to retrieve the information from
the ID hits, which are converted into three-dimensional space points. Then, 
the {\it inside-out} algorithm~\cite{Cornelissen:1020106} is used, starting from a
seed of three aligned hits in the pixel detector or in the SCT.
From there, a path is formed along the seed directional information adding
space points one by one. This is done by using a Kalman filter algorithm~\cite{Fr√ºhwirth1987444}
which checks progressively the compatibility between the track (also progressively updated)
and the new point. The five track parameters described before are also computed at this step.
%As basic requirements, the candidate track must be formed by at least seven points
%measured in the silicon detectors, $d_0$ must be lower than 10~mm and the 
%transverse momentum must be higher than 150~\mev.  
A cleaning procedure then 
rejects incomplete tracks or tracks sharing hits with other tracks,
or composed by %false space points.
noise hits. The candidate tracks are extended
into the TRT and re-fitted taking into account the effects from the interaction
of the charged particle with the detector material. 
%If at least ten TRT hits
%within 10~mm from the extrapolated points the track is kept and re-fitted.

A second algorithm, called {\it outside-in}, is applied in order to better
reconstruct tracks from secondary charged particles. This algorithm does
the opposite of the inside-out one, taking as seeds hits in the TRT (the
ones not associated to any track candidate by the inside-out reconstruction)
and extrapolating back to the SCT and pixel detector.


\section{Primary vertices}\label{sec:primaryvertex}

In general, a primary vertex (PV) is identified by the tracks associated to it.
The reconstruction is performed via an iterative procedure~\cite{ATLAS-CONF-2010-069}
starting from a seed defined as the maximum in the distribution of the $z_0$ parameter
of reconstructed tracks. After tracks are assigned to the PV with the aid of an
iterative $\chi^2$ fit, the ones that fall out of more than 7$\sigma$ from the PV
are used to seed another PV until no track is left without being assigned to a vertex
(a track can be associated to more than one vertex).

A PV must have at least two associated tracks and its position must be consistent with 
the beam collision region in the XY plane. The hard-scatter PV is chosen as the one
with the highest sum of squared transverse moments of the tracks. The other reconstructed PVs 
are identified as pile-up interactions. Another kind of vertices, not
compatible with the requirement of coming from close to the proton collision spot,
are the secondary vertices, originating from the decay of long-lived particles.
These vertices are useful to identify $B$-hadrons and will be described in Section~\ref{sec:btagging}.

As can be expected, high pile-up environments deteriorate the performance of vertex reconstruction,
as the higher density of hits in the tracker may increase
the fraction of misreconstructed tracks and nearby 
pile-up interactions might lead to the misreconstruction
of distinct vertices as a single one~\cite{ATLAS-CONF-2012-042}.

%\footnotetext{Of the reconstructed verteces consistently in the beam collision region in the XY plane with at least five associated tracks, the one with the highest number of tracks is taken as the primary one.}


\section{Energy clusters}\label{sec:clusters}

With the name ``energy cluster'' we generically refer to energy deposits in the calorimeter
cells that are grouped together on the basis of some criteria~\cite{topocluster}.
In particular, we are interested in {\it topological clusters} and {\it electromagnetic towers},
used respectively for hadron and electron/photon reconstruction.

Towers are built using the {\it sliding window} algorithm~\cite{eperf} starting from
single energy deposits in the EM calorimeter middle layer of size
$\Delta\eta\times\Delta\phi=0.025\times0.025$. As schematically shown in Figure~\ref{fig:sliding},
a window of  $3\times5$ cell units is defined, centered on the maximum of
energy and finally expanded to optimize the cluster reconstruction, with a size
that depends on the object (electron or photon) and the position in the detector
($3\times7$ in regions with $|\eta|<1.4$ and $5\times5$ elsewhere).

Topological clusters, abbreviated as ``topoclusters'', are 
built from neighboring calorimeter cells starting from a seed deposit with a signal 
($|E_{\rm cell}|$, the cell measured energy) to noise 
($\sigma$, the RMS of the cell noise distribution from electronic noise
and pile-up) ratio
higher than a certain threshold. Cells with $|E_{\rm cell}|>4\sigma$ 
are taken as seeds, and starting from the
one with the highest $|E_{\rm cell}|/\sigma$ all the neighboring 
cells with $|E_{\rm cell}| > 2\sigma$ are added to the topocluster.
When no more cells above these thresholds are found, all the neighboring
cells, without any cut on $|E_{\rm cell}|$, are added to the topocluster,
according to the scheme commonly referred to as ``4/2/0''.
Topoclusters are treated as massless and their energy at the electromagnetic 
scale is the sum of the constituent cells. Their position and direction parameters
are obtained from a weighted sum of the constituent cells' pseudorapidity and azimuth angle
based on the absolute value cell's energy. Since energy measurement can be negative (due to
noise fluctuations), clusters with negative energies are rejected
when performing jet reconstruction, but still used for \met\ reconstruction.

%%%%AAAAAAAAAAAAA paragraph from v1 jets section
The initial energy is reconstructed at the electromagnetic (EM) scale as
the calorimeter signals arise from electromagnetic interaction of
particles with matter. The energy calibration to EM scale was derived
during test-beam runs using electron beams, validated with muons
from both test-beam and cosmic-rays runs and corrected using simulated $Z\to ee$ events.
In the analyses presented in this dissertation, the Local Cluster calibration
is used to correct for non-compensation, out-of-cluster energy
and dead material effects (see Section~\ref{sec:jescalib}).

\begin{figure}[tb]\begin{center}
        \subfigure{
  	\includegraphics[width=0.85\textwidth]{objectsreconstruction/figures/slidingwindow}}
	\caption{The three steps of the sliding window algorithm.
	\label{fig:sliding}}
\end{center}\end{figure}

\section{Electrons}\label{sec:electrons}

Electrons~\cite{eperf} are reconstructed for pseudorapidities up to $|\eta| = 2.47$, where
information from the ID is available, matching a track (see Section~\ref{sec:tracks}) 
with a cluster in the electromagnetic calorimeter reconstructed with the sliding window 
algorithm (see Section~\ref{sec:clusters}).
In order to account for bremsstrahlung losses the matching is done within a region
of dimension $\Delta\eta\times\Delta\phi=0.05\times0.10$ and if more candidate
tracks are matched, of all the ones with hits in the silicon detectors
the track with the smallest $\dr$ with respect to the
energy cluster is chosen. In addition, the track momentum has to be compatible
with the cluster energy, which is calibrated to the electromagnetic scale
derived from Monte Carlo-based corrections (to account for dead material losses),
test-beam studies and calibration from $Z\to ee$ events~\cite{Abat:1900zz}.

In general, electrons can be distinguished from hadrons thanks to various characteristics
of their shower development: electrons deposit most of their energy in the second layer of
the EM calorimeter; the width of their shower is smaller; they have smaller
hadronic leakage\footnote{The hadronic leakage is the ratio of the transverse energy reconstructed
in the first layer of the hadronic calorimeter to the total  transverse energy reconstructed in the 
EM calorimeter for the cluster.}; the $E/p$ variable (ratio of cluster energy and track momentum) is higher.

Some difficulties arise in presence of energetic
$\pi^0$ and $\eta$ particles, 
which decay into two photons that produce two close 
showers reconstructed as a single one in the second layer of the EM
calorimeter which may happen to overlap with another track from the fragmentation, 
thus potentially resulting in a jet misidentified as an electron.
Other processes leading to the reconstruction of electrons 
not from the primary interaction are tracks from photon conversion
or the semi-leptonic decay of a bottom quark into an electron.
There are then six different electron definitions to help 
separate real electrons from misidentified ones,
described in the following ordered from the looser requirements to the tightest.
Performance studies on electron reconstruction and identification where done using 2010 data and Monte
Carlo $Z\to ee$ and $W\to e\nu$ events~\cite{eperf} (see Figure~\ref{fig:eleeff}). 

\texttt{Loose} electrons lie in the pseudorapidity region $|\eta| < 2.47$ and have 
low hadronic leakage and requirements on the variables defining the shower shape.
The identification efficiency is high but the jet rejection is the lowest
with respect to the other electron definitions (about 500).

\texttt{Loose++} electrons are \texttt{loose} electrons whose track has at least one hit in 
the pixel detector and at least 7 hits in the combined silicon detectors and the
$|\Delta\eta_{\rm first EM}|$ between the track estrapolated to the first EM layer and
the matched cluster is lower than 0.015. The identification
efficiency is similar as for \texttt{loose} one but the rejection is ten times higher.

\texttt{Medium} electrons are \texttt{loose++} electrons where additional requirements on shower shape
are made as well as on their tracks: $|d_0|<$5~mm and $\Delta|\eta_{\rm first EM}|<0.01$.
The efficiency is about 88\% and the rejection is
higher than for \texttt{loose++}.

\texttt{Medium++} electrons are \texttt{medium} electrons whose track has at least one hit in the
first pixel detector layer, a requirement that allows to reject electrons from
photon conversion. Charged hadrons contamination is reduced by discarding candidates
whose track has a low fraction of high-threshold TRT hits. In addition, $\Delta|\eta_{\rm first EM}|<0.005$ 
and stricter cuts are applied to shower shaper of clusters in $|\eta|<2.01$. The
efficiency is about 85\% and rejection is a bit less 50$\times 10^3$.

\texttt{Tight} electrons are \texttt{medium++} electrons with additional requirements on the distance
between the track and the matched cluster ($|\Delta\phi|<0.02$, $|\Delta\eta|<0.005$) and on the $E/p$
variable. Stricter cuts are imposed on the fraction of high-threshold TRT hits and on the impact parameter
($|d_0|<$1~mm). The efficiency is about 75\% and the rejection is slightly higher than 
for \texttt{medium++}.

\texttt{Tight++} electrons are \texttt{tight} electrons with asymmetric $\Delta\phi$ cuts, which give
both better efficiency (about 80\%) and rejection (about 50$\times 10^3$) with respect to \texttt{tight}.

\begin{figure}[tb]\begin{center}
	\subfigure[]{\label{fig:eleeffET}
  	\includegraphics[width=0.45\textwidth]{objectsreconstruction/figures/Figures_EffZee_ET_tight_v2}}
	\subfigure[]{\label{fig:eleeffETA}
  	\includegraphics[width=0.45\textwidth]{objectsreconstruction/figures/Figures_EffZee_eta_tight_20to50_v2}}
	\caption{\texttt{Tight} electron identification efficiencies measured from $Z\to ee$ events and predicted by MC as a function (left) of~\ET\ (integrated over $|\eta|< 2.47$ excluding the transition region $1.37< |\eta|<1.52$ and (right) of~$\eta$ and integrated over $20< \ET<50$~GeV.~\cite{eperf}\label{fig:eleeff}}
\end{center}\end{figure}

The electron energies in data are corrected using $\eta$-dependent  scale factors derived
from data-to-simulation comparison in $Z\to ee$ events in order to match the $Z$ boson 
mass peak.


\tocless\subsection{Additional requirements}\label{sec:REQtrigger}

For our analyses~\cite{topcommon2013}, electrons in the transition region $1.37<|\eta_{\rm cluster}| <1.52$
with inactive material are excluded. Electrons are required to satisfy \texttt{tight++} criteria and to
 have $\et = E_{\rm cluster}/\cosh\eta_{\rm track} > 25\gev$ and $|z_0|<2~$mm.
In addition, to suppress further the QCD multijet background, 
isolation cuts are imposed both as calorimeter (using the energy in a cone of size $\Delta R<0.2$, \texttt{EtCone20})
and track isolation (using the scalar sum of $p_T$s from tracks within a cone of $\Delta R<0.3$, \texttt{PtCone30}). 
%isolation cuts to reduce the background from non-prompt electrons coming from
%hadron decays are defined, one based on the energy from calorimeter cells surrounding the candidate in
%a cone of radius $R=0.2$ and the other based on the track transverse momenta sum in a cone of radius $R=0.3$ around
%the electron.
The \texttt{EtCone20} and \texttt{PtCone30} isolation cuts are chosen to give
90\% efficiency.
In addition, jets (see Section~\ref{sec:jets}) within $\dr =0.2$ of the selected electron are 
discarded, and if an additional jet with $p_T>25~$\gev\  and $|JVF|>0.5$ is found within $\dr =0.4$,
then the electron is rejected.
The selected electron is matched to the single electron trigger \texttt{EF\_e24vhi\_medium1}
combined with a logical \texttt{OR} to the \texttt{EF\_e60\_medium1} trigger, which
recovers some efficiency loss on high transverse energy electrons due
to the isolation cuts of \texttt{EF\_e24vhi\_medium1}. % at $\ET > 80$~GeV.

The efficiency in selecting electrons can be factorized as:
\begin{equation}\label{eq:eleeff}
\varepsilon = \varepsilon_{\rm reco} \cdot\varepsilon_{\rm tight++} \cdot\varepsilon_{\rm isolation} \cdot\varepsilon_{\rm trigger} 
	\end{equation}
where the various components represent respectively: the efficiency in reconstructing the electron 
in terms of track-cluster match, track quality and hadronic leakage; the efficiency
for the \texttt{tight++} identification criteria; the efficiency for the isolation cuts;
the efficiency from trigger selection. Scale factors to match MC to data
are derived in bins of $(\ET,\eta)$,
and the trigger scale factors are separated into four data-taking periods 
(\texttt{A-B3}, \texttt{B4-D3} without \texttt{C1-C5}, \texttt{C1-C5} and \texttt{D4+}).
The efficiency scale factors are applied as weights to Monte Carlo events.

\section{Muons}\label{sec:muons}

As suggested in Figure~\ref{fig:decaychart}, 
muons interact with ATLAS sub-detectors typically 
leaving minimum ionizing particle (mip) signatures in
all of them, i.e. depositing
only a very small fraction of their energy in the material. 
Their track instead is precisely
measured both in the ID and in the muon spectrometer (MS). 
Based on how we decide to combine
the measurements in the different sub-detectors, we can 
distinguish the following types of reconstructed muons:
\texttt{standalone} muons take the MS track and extrapolate it to the interaction point;
\texttt{combined} muons match the MS track with the tracks from the ID;
\texttt{segment tagged} muons extrapolate ID tracks to the spectrometer and match the result with MS segments;
\texttt{calorimeter tagged} muons extrapolate ID tracks to the calorimeters and match the result with
energy deposits. 

We will only consider \texttt{combined} muons, recontructed using an algorithm 
called \texttt{Muid}~\cite{ATLAS-CONF-2011-063} (or ``chain 2'')
and whose pseudorapidity is limited to $|\eta|<2.5$ by the ID acceptance.
Starting from $\Delta\eta\times\Delta\phi=0.4\times0.4$ regions where interesting activity has been triggered,
track segments are searched for in the RPC and TGC and combined into a single track by means of a
least-square fitting method. These track candidates are 
subsequently extrapolated back to the interaction
point and their momentum corrected for the mip energy loss in the calorimeter material.
At this point a \chisq\ test (checking the difference between the extrapolated track coordinates weighted with
combined covariance matrix) on the matching of the candidate MS track and the tracks reconstructed in 
the ID is performed to obtain the final muon candidate track. Only ID tracks that satisfy some quality 
requirements are considered for the matching: they need to have at least two pixel hits, of which at least
one in the first layer; at least two pixel hits plus number of crossed dead pixel sensors; at least six SCT hits
plus number of  crossed dead SCT sensors; a maximum of two pixel or SCT holes\footnote{A ``hole'' in the silicon
detectors is a region where the module did not perform as expected even though the surrounding ones did.};
defining the number of TRT outliers\footnote{``Outlier'' is a hit that is deviated from the track path.} 
and the number of TRT hits as $N_{\rm TRT_{o}}$ and  $N_{\rm TRT_{h}}$ respectively, 
$N_{\rm TRT_{h}}>5$ and $N_{\rm TRT_{o}}/N_{\rm TRT_{h}}<0.9$ for $|\eta|<1.9$, 
$N_{\rm TRT_{o}}/N_{\rm TRT_{h}}<0.9$ if $N_{\rm TRT_{h}}>5$ for  $|\eta|\geq1.9$.
In case no matching is found, no \texttt{combined} 
muons are reconstructed, while if more candidates arise, the one giving the best \chisq\ is chosen.
The momentum is computed as a weighted average of ID and MS measurements.

Performance studies on muon reconstruction and identification done using 2010 data 
from $\rts=7$~\tev\ collisions and Monte Carlo $Z\to \mu\mu$ events~\cite{ATLAS-CONF-2011-063} 
have been recently updated with the data from $\rts=8$~\tev\ pp collisions~\cite{ATLAS-CONF-2013-088}.
The measured reconstruction efficiency for \texttt{combined} muons
is of about 98\% uniformely in pseudorapidity and 
is shown in Figure~\ref{fig:mueff}. 


\begin{figure}[tb]\begin{center}
	%\subfigure[]{\label{fig:mueffET}
  	%\includegraphics[width=0.45\textwidth]{objectsreconstruction/figures/Figures_EffZmumu_pt}}
	%\subfigure[]{\label{fig:mueffETA}
  	%\includegraphics[width=0.45\textwidth]{objectsreconstruction/figures/Figures_EffZmumu_eta}}
	\subfigure{
  	\includegraphics[width=0.6\textwidth]{objectsreconstruction/figures/fig_12b}}
	\caption{\texttt{Combined} muon reconstruction efficiencies using the \texttt{Muid} algorithm 
        (``chain 2'' in the plot label) measured from $Z\to \mu\mu$ events and predicted by MC as a function 
        %(left) of~\pt\ and (right) of~$\eta$.~\cite{ATLAS-CONF-2011-063}\label{fig:mueff}}
        of $\eta$~\cite{ATLAS-CONF-2013-088}.\label{fig:mueff}}
\end{center}\end{figure}


\tocless\subsection{Additional requirements}

\texttt{Combined} muons are used in our analyses~\cite{topcommon2013} with an additional cut on the longitudinal impact
parameter $|z_0|<2~$mm to ensure the track comes  from the hard-scatter primary vertex.
A requirement on the muon momentum of $p_T>25$ is used to obtain 90\% efficiency from the chosen 
single muon trigger, which is the logical \texttt{OR} combination of the 
triggers \texttt{EF\_mu24i\_tight} and \texttt{EF\_mu36\_tight}. 
The \texttt{EF\_mu24i\_tight} trigger includes an isolation requirement 
for which the \pt\ sum of the tracks in a cone of size $\Delta R=0.2$  around the muon
has to be less than the 12\% of the muon transverse momentum.
Muons overlapping with any jet (see Section~\ref{sec:jets}) with $\pt>25$~GeV and $|JVF|>0.5$ 
within a $\Delta R<0.4$ cone are rejected.

In addition to the previous isolation requirements, a ``mini-isolation'' is 
defined~\cite{topcommon2013} to reduce the sensitivity to the high pile-up present
in $\sqrt{s} = $8~TeV collision events.
The mini-isolation is defined as 
\begin{equation}\label{eq:miniisol}
I_{mini}^{\mu} = \sum_{tracks} \pt^{track}/\pt^{\mu}
\end{equation}
where $\pt^{\mu}$ is the muon transverse momentum and the summation runs over
all tracks found in a cone whose radius varies as a function of $\pt^{\mu}$:
\begin{equation}\label{eq:minicone}
\Delta R(\mu,track)=\dfrac{10\gev}{\pt^{\mu}}.
\end{equation}
The tracks also have to satisfy: $\pt^{track}>1~$GeV; $|d_0| < 10$~mm;
$|z_0 \sin\theta_{track}| <10$~mm; at least four hits or dead sensors crossed in the silicon detectors.
The cut on the mini-isolation variable is chosen as $I_{mini}^{\mu}<0.05$.
The performance of the mini-isolation is basically insensitive to pile-up,
being uniformely of about 97\%, while is slightly lower (96\%)
for muons with $\pt^{\mu}<50$~\gev, as 
shown in Figure~\ref{fig:miniisoleff}.

\begin{figure}[tb]\begin{center}
	\subfigure[]{\label{fig:miniisolpt}
  	\includegraphics[width=0.45\textwidth]{objectsreconstruction/figures/miniisol_pt}}
	\subfigure[]{\label{fig:miniisolmu}
  	\includegraphics[width=0.45\textwidth]{objectsreconstruction/figures/miniisol_mu}}
	\caption{Efficiency of the mini-isolation as a function of the muon momentum (left) and of the average number
        of bunch crossings $<\mu>$ (right)~\cite{topcommon2013}.\label{fig:miniisoleff}}
\end{center}\end{figure}


As is done for electrons, a set of corrections are applied to correct for minor
discrepancies between Monte Carlo simulation and data events.
The scale factors to compensate recontruction, isolation and trigger 
inefficiencies are derived from tag-and-probe measurements using $Z\to \mu\mu$ events
and applied to Monte Carlo events. In addition, the muon momentum
in simulated events is smeared to obtain agreement between the momentum
resolutions in Monte Carlo and data.


\section{Jets}\label{sec:jets}

With the name ``jet'' we generically refer to the object formed as a consequence
of the hadronization of a spray (or {\it jet}) of partons. The resulting stable particles
will leave signals both as tracks in the ID and as energy deposits in the calorimeters
and two type of jets can then be defined using either the former or the latter information:
track jets and calorimeter jets. In the following, we will only discuss calorimeter jets.

In order to interpret the detector information, first topoclusters are formed from the
calorimeter cells signals, as explained in Section~\ref{sec:clusters}. Then, different
algorithms were developed to associate topoclusters into a jet. Because of the
need for a stable and precise performance over the QCD processes from pp collisions,
a set of requirements has been defined for the algorithms to be valid~\cite{Salam:2009jx}.

First of all, the splitting of one particle into two collinear particles 
or the presence of additional soft emission must not change the 
result of the algorithm reconstruction.
The importance of this so-called Infrared and Collinear (IRC) safety is evident considering e.g. 
that a hard parton, as part of the fragmentation process, will undergo many collinear splittings,
and that QCD events always include emission of some soft particles, perturbatively or not.
In addition, we want the algorithm result to be invariant under a Lorentz boost along the beam direction,
to be as insensitive as possible to detector effects like noise or resolution, and to be light in terms
of  usage of computing resourse.

A set of jets algorithm that satisfy these requirements are the sequential recombination
algorithms~\cite{ref:Cacciari2008,ref:Cacciari2006,ref:fastjet}, which combine topoclusters
into jets using as criteria a distance parameter defined as:
\begin{equation}
d_{ij}=min(p_{T_i}^{2p},p_{T_j}^{2p})\frac{\Delta R_{ij}^{2}}{R^{2}},
\end{equation}
\begin{equation}
d_{i}=p_{T_i}^{2p},
\end{equation}
where $p_{Ti}$ is the transverse momentum of topocluster $i$, 
$\Delta R_{ij}$=$\sqrt{(\Delta\eta_{ij})^{2}+(\Delta\phi_{ij})^{2}}$ the distance 
between constituents $i$ and
$j$, $R_{ij}$ a parameter of the algorithm that approximately controls the size
of the jet, and $p$ is a  parameter that defines the type of algorithm as:
\begin{equation}\label{eq:jetalgp}
\begin{array}{lcl}
p = 1 &:& k_t {\rm\ algorithm};\\
p = 0 &:& {\rm Cambridge/Aachen\ algorithm};\\
p = -1 &:& {\rm anti-}k_t {\rm\ algorithm}.
\end{array}
\end{equation}

The algorithms compute $d_{ij}$, the distance between the two topocluster
inputs $i$ and $j$, and $d_{i}$,  the distance between the input $i$
and the beam axis in the momentum space.
By computing the minimum of the two distances the choice made is
to combine $i$ and $j$ into a new input if $d_{ij}<d_{i}$, or take
$i$ as a jet candidate and remove it from the input list if $d_{i}<d_{ij}$. 
The cluster combination is done by summing the four-momentum of each input.
The distances are recalculated with the updated list of input
objects and the process repeated until no further cluster is left.

The anti-$k_t$ algorithm is chosen by most of analyses in ATLAS as it is particularly 
performant against pile-up, since it starts summing up 
constituents with higher momentum, and produces jets with a conical
structure (see Figure~\ref{fig:jetshapes}).

\begin{figure}[tb]\begin{center}
	\subfigure[]{\label{fig:jetshapes}
  	\includegraphics[width=0.5\textwidth]{objectsreconstruction/figures/jetshapes}}
        \subfigure[]{\label{fig:corr_jet}
        \includegraphics[width=0.47\textwidth]{objectsreconstruction/figures/corr_jet_lcw.eps}}
        \caption{Left: The same input produces different results in terms of jet reconstruction using 
        various jet algorithms~\cite{Salam:2009jx}. Right: Average jet energy response from simualted events
        at the LCW scale for various calibrated energies ($E$) as a function of
        pseudo-rapidity. The inverse of the response shown 
        in each bin is equal to the average jet energy scale correction~\cite{jes}.}
\end{center}\end{figure}


\tocless\subsection{Jet energy calibration}\label{sec:jescalib}
For our analyses~\cite{topcommon2013} jets are 
reconstructed using the anti-$k_t$
algorithm with a radius parameter $R=0.4$ 
(\texttt{AKT4} algorithm) 
using calorimeter energy deposits corrected for 
pile-up energy deposits, effects 
of non-compensation\footnote{The energy response 
to hadrons is lower than the response to electrons of the 
same energy due to the presence of invisible processes.},
dead detector material and out-of-cluster leakage.
Other effects affecting jet energy are low momentum particles
that are deflected by the magnetic field and energy losses in 
topocluster formation and jet reconstruction~\cite{jes}. 
Jet energy, measured at the EM scale,
is calibrated to the hadronic scale following 
a calibration scheme.
Of the several energy calibration schemes 
derived in ATLAS, we will be using the 
Local Cluster Weighting (LCW) calibration~\cite{LCW1,LCW2}.
This scheme exploits properties of the topoclusters shapes 
to classify the clusters as ``mainly electromagnetic'' or
``mainly hadronic'' and then derives the calibration from 
Monte Carlo simulation of charged and neutral pion events. 
The correction factors are $\pt$- and $\eta$-dependent
and obtained from a Monte Carlo sample of \texttt{MC12a}
\texttt{PYTHIA} inclusive QCD jet events.

The calibration corrections are applied 
before the jet reconstruction algorithm is operated, and after 
the jet is formed a pile-up correction
is applied in order to subtract the average
extra energy coming from pp interactions in
the same or in other bunch crossings.
This pile-up correction depends on the number of primary vertices in an event ($NPV$),
on the number of average interactions in 
a luminosity block ($<\mu>$), and is derived in bins of jet $\eta$ in order to
account for the different geometries of the detector. The
correction is applied to bring all objects to a 
reference point with $\mu=0$ and $NPV = 1$

Finally the jet energy is corrected to the particle
level using a jet energy scale factor obtained
from a Monte Carlo sample which does not include
multiple pp interactions, as these have been already
corrected for.
The jets used for the calibration are isolated jets\footnote{Here an
isolated jet is a jet which does not have any other
jet with $\pt>7\gev$
around a $\Delta R$ cone of 2.5$R$, where $R$ is
the jet algorithm paramenter, i.e., for the \texttt{AKT4}, 0.4}
reconstructed in the calorimeter and matched to
a truth-level jet (also isolated) within $\Delta R<0.3$
The simulated jet energy response 
is the ratio between the energy measured in the LC jets ($E_{\rm LC}^j$)
and the truth jet energy ($E_{\rm truth}^j$). It is measured in bins of
the truth jet energy and of the calorimeter jet pseudorapidity $\eta_{\rm det}$
and a bin-by-bin fit is performed to obtain a
calibration function in terms of $E_{\rm LC}^j$
binned in $\eta_{\rm det}$.
The calorimeter jet response is
shown in Figure~\ref{fig:corr_jet}
as a function of $\eta_{\rm det}$
for some values of the jet energy.


%%%%%%%%%%%%% EM+JES????? start

%First a pile-up correction
%is applied in order to subtract the average
%extra energy coming from pp interactions in
%the same bunch crossing and have an energy
%measurement independent from the instantaneous
%luminosity. Using mimimum bias data
%an offset correction dependent on the number
%of reconstructed PVs ($N_{\rm PV}$), the bunch
%spacing (allowing to account for out-of-time
%pile-up) and the jet $\eta$ (in order to 
%account for the different geometries of the
%detector) is obtained. 

%Then a vertex correction is applied to
%fix the direction of the jet to point 
%towards the PV instead of the geometrical
%center of the detector. As a consequence the
%topocluster kinematic observables 
%need to be re-computed. 

%Finally the jet energy is corrected.

%%%%%%%%%%%%% EM+JES????? end




%hmmmmmm AAAAAAAAA anche a 8 tev???
%To subtract contributions from in-time and out-of-time pile-up interactions a correction is applied
%parameterized according to the number of primary vertices in the event and the number of average interactions 
%in the luminosity block ($<\mu>$) as a function of jet pseudorapidity.

\myskip
\tocless\subsection{$b$-tagging}~\label{sec:btagging}
When a bottom quark is produced in an event, it hadronizes into a $B$ hadron, which has
a lifetime of the order of $10^{-12}$~s and hence can travel about 3~mm before decaying.
The result is a displaced secondary vertex that, if correctly reconstructed, can
allow for the identification of the bottom quark. 
Since this capacity relies on track reconstruction from the ID, its applicability
is limited by the ID acceptance to the pseudorapidity region $|\eta|<2.5$.

\begin{figure}[tb]\begin{center}
	\subfigure{
  	\includegraphics[width=0.5\textwidth]{objectsreconstruction/figures/Picture-b-tagging-2}}
	\caption{Simple schematic of the displaced secondary vertex.\label{fig:btagvtx}}
\end{center}\end{figure}

This technique is called $b$-tagging~\cite{ref:ATLAS-CONF-2011-102} and is
widely used in ATLAS analyses with top quarks. There are three types of algorithms,
and they can be combined to obtain better performance. In general they define a weight
corresponding to the probability for the jet to be tagged, and a working point is chosen
as the threshold for this weight to discriminate between $b$- and non-\bjet s
by finding a good compromise between efficiency (the ratio between tagged
$b$-jets and true $b$-jets) and light-jet rejection
(the inverse of the number of light-jets misidentified as $b$-jets).

Algorithms like \texttt{IP3D} are
based on information from the impact parameters of the tracks
contained in the jet, $z_0/\sigma_{z_0}$ and $d_0/\sigma_{d_0}$,
with respect to the reconstructed PV. 
A likelihood is computed to
obtain the $b$-tag weight for the jet.

Other algorithms reconstruct the secondary vertex from the $B$ hadron
decay, allowing for a better discrimination between \bjet s and light
jets. The \texttt{SV1} algorithm uses the number of track pairs in
the secondary vertex, their total invariant mass and the ratio of
the sum of the energies of tracks from the secondary vertex to the one
of the total tracks of the jet to compute likelihood ratios, the logarithms
of which are summed to define the $b$-tag weight of the jet.

Finally, the \texttt{JetFitter} algorithm performs a reconstruction
of the full decay chain of $B$ and $C$ hadrons by using a Kalman filter to determine a 
common path between the primary vertex and the vertices from the $b$ and $c$ hadrons 
inside the jet. The likelihood is computed with the decay length significances
of the vertices and the variables from the  \texttt{SV1} algorithm.

The algorithm employed in our analyses is called \texttt{MV1} and uses
a neural network to combine information from the \texttt{JetFitter}, \texttt{IP3D}
and \texttt{SV1} algorithms.
The working point corresponding to 70\% efficiency, 
$\sim$130 light-jet rejection and a charm-jet rejection of 5 is 
chosen (see Figure~\ref{fig:btageffs}).

\begin{figure}[tb]\begin{center}
	\subfigure{
  	\includegraphics[width=0.98\textwidth]{objectsreconstruction/figures/btageffs}}
	\caption{Light- (left) and $c-$jet (right) rejection as a function of the \bjet\ tagging efficiency
        for different tagging algorithms. These values refer to jets with $\pt >15\gev$ and 
$|\eta|<2.5$ in simulated $t\bar{t}$ events~\cite{btagging}.\label{fig:btageffs}}
\end{center}\end{figure}

The tagging efficiencies in Monte Carlo are corrected for 
$b$, $c$ and light flavours~\cite{btagging,ctagging,ltagging}
with the appropriate $\epsilon_{data}/\epsilon_{MC}$ scale factors,
determined in bins of jet $\pt$ and $\eta$.
These efficiency are obtained for \bjet s from di-jet samples with
muons in the final states using the {\it  $\pt^{\rm rel}$ method},
which exploits the variable $\pt^{\rm rel}$ (the momentum of the
muon transverse to the axis of the system formed by the muon and the jet)
to distinguish muons from a $b$-flavor jet (harder  $\pt^{\rm rel}$ spectrum)
from muons from $c$- and light-flavor jets. 
%The sample used to derive the $\pt^{\rm rel}$ template for 
%$b$-flavor jets has enhanced heavy-flavour content, while
%The template for light-flavor jets is derived from a data sample
%where another algorithm (\texttt{IP3D+SV1} at the 80\% efficiency working point) 
%is used to veto \btag ged jets.
The $c$-tagging efficiency, i.e. the efficiency with which jets from $C$ hadrons
are tagged by the \btag ging algorithm, is measured in samples of jets
with $D^*$ mesons, where the yields of $D^*$ mesons before and after \btag ging
are compared.
The scale factors for light-flavour jets, also referred to as 
{\it mistag rate}, are derived from the fraction of \btag ged jets originating 
from light flavour. The mistag rate is measured in an inclusive jet sample, using the
{\it negative tag method}, where the impact parameter significance sign of tracks
(for ``impact parameter based'' \btag ging algorithms) or the decay 
length significance sign of secondary vertices
(for ``secondary vertex based'' \btag ging algorithms) is reversed.


\myskip
\tocless\subsubsection{Tag Rate Function method}\label{sec:trf}
When requiring $\geq 1$ $b$-tagged jet the
available Monte Carlo statistics is significantly reduced for 
some particular background processes, leading to large
fluctuations in the resulting distributions.
To overcome this problem the Tag Rate Function (TRF) method is introduced.
Here, no event is rejected based on its $b$-tagging count, 
but instead all the events are 
kept and weighted according to the
probability of the given event to contain the desired number of \bjet s.
Appendix~\ref{app:trf} describes the TRF method in more detail.

\myskip
\tocless\subsection{Additional requirements}
In our analyses we consider only jets with $\pt > 25\gev$ and $|\eta| < 2.5$.
Furthermore, a variable called ``jet vertex fraction" (JVF) is defined as the fraction
of the sum of $\pt$ of tracks with $\pt>1\gev$
associated with the jet that comes from tracks originating from the primary vertex.
By requiring JVF$>0.5$ we avoid selecting jets from in-time pile-up events.

To avoid double counting of energy deposits from electrons as jets,
if jets are found within $\Delta R$ of 0.2 of the selected electron, the
jet closest to the electron is removed. 
%and then electrons that lie within $\Delta R< 0.4$ of the remaining jets are discarded.


\section{Missing Transverse Energy}\label{sec:met}

To estimate the momentum of invisible particles in the event, i.e. neutrinos and, eventually, new particles,
the missing transverse energy $\met$~\cite{met} is defined~\cite{topcommon2013} to balance the total transverse momentum of the event.
Indeed, while the longitudinal energy of the interacting partons is unknown, as they carry an unpredictable
fraction of the total proton momentum, its transverse component is, initially, zero.
Possible sources of \met\ mismeasurements are
insufficient detector coverage, dead or noisy regions and
finite detector resolution.

The \met\ is computed by first matching each topocluster
with a high-$\pt$ object,  in the following order: electrons, photons, jets and muons.
These are respectively the RefEle, RefGamma, RefJet, RefMuon terms, while 
the low-$\pt$ jets (10$<\pt<20$~\gev)
are grouped into the SoftJet term. Then, the energies of these objects are
corrected accordingly to the respective calibration constants. 
The calorimeter clusters
that did not get associated with any  high-$\pt$ object are calibrated for energy losses in 
dead material regions and for the different response to the electromagnetic and hadronic
components of particle showers and added as the CellOut term. 
Finally the \met\ is computed as:
\begin{equation}\label{eq:met}
\begin{array}{lcl}
%E^{\rm miss}_{x,y} & = & E^{\rm RefEle}_{x,y} + E^{\rm RefGamma}_{x,y} + E^{\rm RefJet}_{x,y} + E^{\rm RefMuon}_{x,y} + E^{\rm SoftJet}_{x,y} + E^{\rm CellOut}_{x,y}\\
E^{\rm miss}_{T} & = & \big|-\sum\vec{p}_T \big| = \sqrt{(E^{\rm miss}_{x})^2 + (E^{\rm miss}_{y})^2} ,\\
E^{\rm miss}_{x} & = & -\sum\vec{p}_x ,\\
E^{\rm miss}_{y} & = & -\sum\vec{p}_y ,\\
\end{array}	\end{equation}
where the sums run over all the objects previously listed.

%\subsection{Additional requirements for analyses}
